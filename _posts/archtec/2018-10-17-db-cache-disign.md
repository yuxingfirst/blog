---
title: 几则基础技术问题总结
layout: post
categories: [架构设计]
tags: [技术心得]
description:   .
--- 

## 查看服务器负载的指标和含义
我们可以通过运行`top`（`uptime`、`w`也可以）来查看服务器的负载`load average`， 一般load average是这样展示的：`load average: 0.10, 0.15, 0.14`
三个数值分别表示1分钟、5分钟、15分钟内系统的平均负载，具体负载的含义解释可以参考文章：[Understanding load averages](http://blog.scoutapp.com/articles/2009/07/31/understanding-load-averages)， 我们主要来看看如何评估我们的系统是否高负载了。
判断是否高负载时， 我们会选用15分钟内的平均负载， 因为1分钟或者5分钟由于时间太短可能是一些临时性任务造成的， 15分钟内的平均负载比较有参考意义。一般我们以 loadavg/cpu核心数 来判断， 这个数值一般不要超过0.7， 大于0.7说明系统负载比较高。
如果遇到系统高负载时是否说明一定CPU的问题呢？这个倒不一定，要根据机器上跑的具体服务来看是CPU密集型、网络密集型还是IO密集型来区分， Load高只是表象， 深层导致load高的因素需要另外去甄别， 可以利用iostat、netstat等这些命令来查看。

## 数据库读写的优化思路
在DB的实际应用中碰到性能问题时， 一般是DB响应时间变长、负载变高等等， 首先要问问是否真的有必要做架构上的优化， 应该先梳理看看我们业务逻辑中的sql是否有慢查询、各条业务sql是否都有效命中了索引、表结构设计是否合理、索引设计是否合理、业务的查询逻辑是否合理， 做完了这些再来评估当前的DB架构是否真的无法满足业务规模， 此时在做架构上的优化还不迟。
此外，在做架构优化之前， 也还可以想想是否可以选用更好的机器（譬如更多核的CPU、更大内存、SSD等等）来解决当前的问题。 就DB这块来看我们说要优化， 无非是DB已经成为了当前架构的瓶颈， 我们要通过引入一些额外的模块（例如缓存）来解决DB瓶颈的问题， 这又增加了整体业务架构的复杂度， 随之而来的是技术开发维护成本、运维成本的增加， 可能还要考虑数据一致性、实时性的问题。所以我们看通过选用更好的机器来部署DB解决当前的瓶颈问题， 整体架构得以继续保持简洁， 也不失为一种好的选择。
到底怎么做，需要我们根据业务面临的实际情况来评估，选择一种最合适的方案。
再说到DB读写的优化， 我们熟知的有MySQL主从分离、Cache、分库分表等等， 具体选用哪一种，需要结合业务模型，是读多写少、还是写多读少、具体读写比例、读写逻辑是否存在事务性要求等等。
MySQL主从分离的架构一般是用于读多写少的业务， 业务层将读写请求区分开来分别发送到Master和Slave， 以解决单台DB能力不足的问题。由于MySQL本身就支持主从的架构所以实施起来不是很难，但是也存在一些问题， 例如主从同步延迟、数据一致性问题， 如果业务对数据实时性要求很高，需要考虑一些解决预案。
Cache解决的也是读的问题， 架构层面需要引入一层cache的时候肯定需要评估好单纯的主从分离也无法满足业务规模了，所以需要引入cache来应对更大的请求量。cache的选型有很多，纯KV的(memcache、ckv等)，Redis、MongoDB这些有更丰富数据结构的， 另外sphinx也算， 具体选择哪种要根据哪些数据放进cache以及数据结构、读写模型来定。还需要考虑数据如何同步，双写、消息队列还是走Binlog同步， 另外就是数据一致性、实时性等。
如果业务的读写量都很大， MySQL主从架构中单master可能无法承载大的写量、Cache架构下可能数据延迟问题会更严重。 此时可以考虑读写都从MySQL剥离出来全部采用NoSQL存储来解决； 又或者是对业务数据进行分库(垂直拆分)还是进行数据表的拆分(水平拆分sharding)来分散DB读写压力的问题。 

## 常见的负载均衡策略
一般我们业务的整体架构是分多层的， 对于最上层的接入、web层，最原始的负载均衡可以采用DNS，不过由于DNS的延迟问题以及无法感知业务svr的真实负载情况，所以一般很少用来做负载均衡。 开源领域常见的负载均衡组件有LVS、Nginx、HAProxy， LVS工作于网络层，通常用来做四层负载均衡设备， Nginx、HAProxy既可以做四层负载均衡，又可以做七层负载均衡。公司内部的话有TGW、L5，L5一般用来做业务逻辑层的负载均衡。
此外我们还应该继续探讨  1：为什么需要做负载均衡？  2：怎么做？

### 为什么需要负载均衡
在讨论为什么需要负载均衡之前， 先来明确一下， 什么是负载均衡？
我们知道， 在一个业务_系统发展过程中， 随着业务规模_流量的增长， 整体架构一般是由单机向多机分布式来演进的， 业务发展初期流量小，单机架构就能满足业务需求， 负载均衡也不是此刻需要考虑的问题； 不过当我们的系统变成多机分布式的架构时， 例如一个业务部署了10台机器同时对外提供服务， 如何确保能提供10倍于单机的服务能力， 每台机器都能服务到同等规模的流量，不至于“饱饿”不均， 此时选择合适的负载均衡策略就很重要了。
至于为什么需要负载均衡， 就很明了了。 单个实例所能承受的负载是有限的， 当针对单实例进行平行扩容时整个系统的负载能力可以线性提升， 此时就需要做负载均衡。

### 负载均衡怎么做
类似这个题开头讲到的， 一般业界都会有一些优秀的开源组件来帮助我们做这个事； 但是具体是否有适用还需要进一步去评估我们的业务问题，不过通常应该都能找到合适的， 没有造轮子的必要。
另外也有一些比较常见的负载均衡算法来决定如何选取后端节点， 例如： 随机、轮训、hash、 动态选择，每一种都有其有点和缺点，需要我们自己去权衡。 
例如选择Nginx，nginx提供了几种内置负载均衡方案[nginx load balancer](http://nginx.org/en/docs/http/load_balancing.html)供我们选择， 不过这些方案都是固定的没法根据实际负载情况动态适应， 因为后端部署服务的机器配置可能不全相同， 这就导致不同节点的服务能力是不同的； 
又例如公司内部的L5， 是根据请求延时、成功率、请求数这些指标来计算权重， 这种策略要比固定配置的策略要好，因为是可以自适应的。

## TCP、UDP的区别和深入分析
学习过网络编程的同学都知道TCP、UDP两个协议是网络编程中最基础的两个协议之一， 一般我们被问到TCP或者UDP时都知道TCP是基于连接的、UDP是无连接的， TCP是流式协议、UDP是数据报协议，那么再这些术语背后我们怎么去理解呢？ 下边来着手分析。

### 连接
我们说TCP是可靠的网络传输协议， 而由于网络的不稳定性，数据在传输的过程中很容易丢失、乱序，所以TCP为了确保“可靠性”， 即发送方发送什么数据接收方一定要收到、并且发送方发送数据的顺序是什么则接收方接受到的数据顺序也要是一致的，于是要求通信双方在通信之前，必须建立“连接”，也就是说双方在通信之前需要互相确认”已经准备好了”，类似我们打电话之后需要先拨号。 而所谓的“连接”也不是说有一个实际的物理连接(当然数据链路层会有)， 只不过是在通讯双方维护的一个“连接状态”， TCP认为只有当一个“连接”状态为ESTABLISHED时双方才可以进行数据传输， 在实际编程中一般是connect与accept返回后我就可以进行数据的send与recv。 我们所熟知的三次握手、四次挥手也即套接字不同状态的变迁，如下图：
![](2018-10-17-db-cache-disign/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_9e1ca90b-79ce-44f5-b6a5-a95221d91bcc.png)

而UDP由于其本身的不可靠性， 并不需要像TCP那样需要具备重传、排序的特性， 他所做的就是知道对方的地址、然后把数据发送出去，并不需要“连接”。

另外比较TCP和UDP的包头协议可以看到， TCP的包头字段复杂很多， 像Sequence Number、Acknowledgment Number、Window这些字段是UDP协议头中没有的， 而这些字段正是TCP解决诸如： 丢包重传、乱序、拥塞控制所必须的， 在TCP建立连接时这些字段值都会协商好。
![](2018-10-17-db-cache-disign/tcp.png) 
![](2018-10-17-db-cache-disign/udp.png)

### 编码
我们在编写服务代码的过程中， 当传输层协议采用TCP或者UDP时，发送一个2000Byte的数据包是否会有不同？

#### MTU/IP分片 
我们知道在TCP/IP的分层网络中， 每一种物理网络都会规定链路层数据帧的最大长度，称为链路层MTU；并且不同的物理网络其MTU是不一样的，当数据帧长度超过MTU时会被丢弃的 。 所以再IP层发送数据包时， 需要确保发送的数据不会超过MTU； 而当数据大小超过MTU时， 就需要把数据分多次发送，这个过程即IP分片。 
大部分网络协议格式都是协议头+数据的形式，IP协议头一般是20字节， 数据链路层数据帧头一般是8字节，例如我们所熟知的以太网MTU为1500字节， 所以理论上IP层一次所能发送的数据最大为1500 - 20 - 8 = 1470字节。
然而， IP分片虽然解决了不同网络MTU不同的问题， 但是也带来了新的问题， 首先是性能降低， 一次能传输的数据需要分多次； 另外就是由于网络的不稳定性， 一份数据包分多次传输增大了丢包的风险，同时由于IP协议并没有超时重传逻辑，即便只有一个分片丢失也需要重传整个数据包， 所以某些时候我们也需要避免分片。

OK， 再回到初始的问题， 由于TCP是流式传输， 而UDP是数据报传输， 怎么理解呢？  在TCP协议中， `send(2000Byte)`
只是把要发送的2000Byte数据写到了TCP发送缓冲区，TCP层最终发送到IP层的数据并不一定是2000Byte，实际发送的数据是受滑动窗口/拥塞窗口等等因素综合决定的； 而如果是UDP协议的话， `send(2000Byte)`最终一定是把这份2000Byte的数据发送到了IP层， 如果此时这份数据大于MTU， 则在IP层会分片， 由于UDP并不具备重传逻辑， 如果传输过程中发送错误造成分片丢失， 则整个UDP数据包有丢包风险。相反TCP因为有超时重传这些机制则不会有这个问题。

所以当我们的服务使用UDP协议时，编码过程中要尽量避免分片。

## 数据访问加速方案
这个标题起的比较泛， 根据我们所服务业务的不同会有不同的解决方案， 譬如web(H5)、APP、音视频直播等等。另外在考虑加速方案之前， 首先要明确我们的技术(优化)方案是要提供更好的用户体验，  比如H5页面的首屏优化、音视频直播/录播的首次缓冲延时等等都是要给用户一种“快”的直观感受，减少用户等待时间。详细的方案不细表了， 需要根据具体的业务逻辑场景来分析每一个步骤的耗时，然后逐个击破。大致来说有一些策略，例如： 预加载、  IP直出、数据分片、并行化等等。

## WEB常见漏洞和规避方法
谈到漏洞这块我看更多的是要求我们在写代码时要更多的考虑如何确保系统的健壮性。我了解几个比较常见的有SQL注入、XSS、逻辑漏洞等， 更详细的参考[常见web安全漏洞](https://www.jianshu.com/p/6ca57c2a4d8b)， 由于我之前主要用DB，碰到的SQL注入情况比较多，这里在讲下。
防止SQL注入最重要的一点就是不要直接拼SQL， 而一定要采用参数化查询的方式；另外就是对于外部传入的参数， 一定要做合法性检查， 除了判空之外还需要判断下参数的类型是不是跟代码期望的类型一致。 除此之外就是参数内容，通常绝大多数SQL注入攻击都会有一些特定的内容(例如公司安全平台的扫描)， 在参数检查时也可以针对内容判断是否合法。
逻辑漏洞的话更多的可能是写代码时考虑不够周全，所以在日常的编码工作中要多考虑下一些异常情况，多问自己几个 “如果”。

#技术心得#
